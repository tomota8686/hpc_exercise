# ネットワーク系演習II 高能率計算 1回目レポート
## 学籍番号：32114023

## 名前：岩越 智貴

## 使用計算機環境情報
* CSE
* コンパイラ: g++

# 課題１
ソースコードの計測部分前後にタイマー関数を追記して実行速度を計測した．

## 結果
10回実行した結果の実行時間の例を以下に示す．
mul_timeが行列積の計算時間、mul_addが行列和の計算時間である。

exercise 1: loop = 10, size = 3
|count|mul_time    |add_time   |
|-----|------------|-----------|
|    0|0.000275    |0.001353   |
|    1|0.000102    |0.000171   |
|    2|8.7e-05     |0.000125   |
|    3|6.1e-05     |0.000169   |
|    4|6.7e-05     |0.000129   |
|    5|0.000101    |0.000143   |
|    6|7.7e-05     |0.000121   |
|    7|0.000837    |0.000118   |
|    8|6e-05       |0.000186   |
|    9|6e-05       |0.000139   |
||||
|  avg|0.000161333 |0.000144556|

## 考察
行列積の計算時間は何度試行しても、7回目の計算に時間がかかった。
1回目の計算に7回目を除くと、時間がかかっていることがわかる。
また、行列和の計算は、1回目の試行に時間が他の10倍程度かかっていることがわかる。

# 課題２
コンパイラオプションをO0~Ofastに変えてプログラムをコンパイルした．

## 結果
結果は以下のようになった．

exercise 2: loop = 100, size = 1024

|option|time [ms]|
|------|---------|
|none  |38.8705  |
|-O0   |39.0309  |
|-O1   |10.267   |
|-O2   |8.10946  |
|-O3   |3.42826  |
|-Ofast|2.74398  |

またコンパイル時間を下記に示す．
```shell-session 
cmj14023@cs-d42:~/lec/hpc_exercise/src/hpc-exercise > time make
g++ -std=c++0x -fopenmp -Wno-unused-result -march=native -O0    -c -o utils/mat.o utils/mat.cpp
g++ -std=c++0x -fopenmp -Wno-unused-result -march=native -O0    -c -o utils/mat_util.o utils/mat_util.cpp
g++ -std=c++0x -fopenmp -Wno-unused-result -march=native -O0    -c -o main.o main.cpp
g++ -std=c++0x -fopenmp -Wno-unused-result -march=native -O0  -o hpc_exercise utils/mat.o utils/mat_util.o main.o

real    0m1.753s
user    0m1.524s
sys     0m0.156s

cmj14023@cs-d42:~/lec/hpc_exercise/src/hpc-exercise > time make
g++ -std=c++0x -fopenmp -Wno-unused-result -march=native -Ofast    -c -o utils/mat.o utils/mat.cpp
g++ -std=c++0x -fopenmp -Wno-unused-result -march=native -Ofast    -c -o utils/mat_util.o utils/mat_util.cpp
g++ -std=c++0x -fopenmp -Wno-unused-result -march=native -Ofast    -c -o main.o main.cpp
g++ -std=c++0x -fopenmp -Wno-unused-result -march=native -Ofast  -o hpc_exercise utils/mat.o utils/mat_util.o main.o

real    0m3.692s
user    0m3.464s
sys     0m0.164s
```

## 考察
何もしない場合と-O0、-O1、-O2、-O3、-Ofastを試した。実行速度は、-O0が一番遅く、-Ofastが一番速いという結果になった。
一方、コンパイルにかかった時間は、-OFastが一番遅く、-O0が一番速いという結果になった。

# 課題３

## <はじめに>
古典的な高速化技法では、プログラムを書き換えることにより高速化をはかる。
コンパイラオプションで最適化を図ると、今回の効果を確認しづらくなってしまう。
このことより、課題3から課題12まではコンパイルオプションは以下のとおりとする。
```Makefile
CXXFLAGS = -std=c++0x -fopenmp -Wno-unused-result -march=native
```

以下のようにコードを書き換えた．

書き換え前
```cpp
const float v = x.data[i];
ret.data[i] = 3.f * v * v * v * v * v * v
    + 3.f * v * v * v * v * v
    + 3.f * v * v * v * v
    + 3.f;
```
書き換え後
```cpp
const float v = x.data[i];
y.data[i] = 3.f * ((v * v * v * (v * (v * (v + 1.f) + 1.f) + 1.f)) +1.f);
```

## 結果
計算速度は以下のとおりとなった。
|method|time [ms]|
|------|---------|
|before|0.0249922|
|after |0.0108397|

## 考察
ホーナー法を使った場合、使わない場合に比べて約1.5倍早くなっている。


# 課題４
小さな行列に対して、各要素xを下記の定数倍するプログラムを作成し、数式の展開前後で計算速度を比較する。
```math
(2\pi+\sqrt{5}+0.5^{2})x
```

## 毎回計算をする場合
毎回計算をするコードは以下のとおりである。
```cpp
for (int i = 0; i < s; i++)
{
    //計算 ansに書き込み
    const float v = x.data[i];
    ans.data[i] = (2.f * M_PI + sqrt(5) + pow(3.f, 2.0)) * v;
}
```

## 先に共通部分を計算する場合
先に共通部分を計算する場合は以下のとおりである。
```cpp
//定数値を計算
const float tmp = 2.f * M_PI + sqrt(5) + pow(3.f, 2.0);
for (int i = 0; i < s; i++)
{
    //計算 yに書き込み
    const float v = x.data[i];
    y.data[i] = tmp * v;
}
```

## 結果
計算速度は以下に示す。
|method |time [ms]|
|-------|---------|
|inline |0.110791|
|precomp|0.00631822|

## 考察
この計算を比較した結果から、10のマイナス2乗ほどの違いが発生した。
これより、主記憶からレジスタにデータを運ぶ速度のほうが、ALUでの乗算速度より10のマイナス2乗程度速いことがわかる。

# 課題5
小さな行列に対して、各要素を3.141592で除算する計算をするプログラムを作成する。
除算を避ける場合とそうでない場合での効果を比較する。

3.141592の除算を、除算を使うパターンと1/3.141592をもともと計算をしておいて、それを乗算するパターンとを試した。
また、2重ループで実装したパターンと1重ループの場合とを試した。

```cpp
//2重ループ除算
ans.data[ans.index(j, i)] = x.data[ans.index(j, i)] / 3.141592;
//2重ループ乗算
float tmp = (float)1 / 3.141592;
y.data[y.index(j, i)] = x.data[ans.index(j, i)] * tmp;
//1重ループ除算
ans.data[s] = x.data[s] / 3.141592;
//1重ループ乗算
y.data[size] = x.data[size] * tmp;
```

## 結果
計算速度は以下に示す。
|method |time [ms]|
|-------|---------|
|div 2lp|0.0641616|
|mul 2lp|0.0588628|
|div 1lp|0.0217689|
|mul 2lp|0.0199857|

## 考察
確かに除算計算において素直に除算を使うより、すでに計算しておいた除算式をループの中で乗算するほうが速いことが読み取れる。また、多重ループより1重ループのほうが速度が速いこともわかる。しかし、それほど違いが出ていない。最近の計算能力的に乗算速度と除算速度は違いが小さくなってきているのではないか。

# 課題6
小さな4つの行列ABCDに対して行列の各要素ごとに計算をするプログラムを作成し、順序を入れ替えて除算を削減する前と後で計算速度を比較する。

## 普通に計算した場合
```cpp
ans.data[ans.index(j, i)] = (a.data[a.index(j,i)] / b.data[b.index(j, i)]) * (c.data[c.index(j,i)] / d.data[d.index(j, i)]);
```
## 除算を削減した場合
```cpp
ret.data[ret.index(j, i)] = (a.data[a.index(j,i)] * c.data[c.index(j, i)]) / (b.data[b.index(j,i)] / d.data[d.index(j, i)]);
```

## 結果
計算速度は以下に示す。
|method|time [ms]|
|------|---------|
|div x2|0.0350413|
|div x1|0.03393|

## 考察
確かに、普通に計算するより除算を削減したほうが速いという結果となった。しかし、思ったより、速度に違いは出なかった。これも先の課題5で考察した通り、除算と乗算の速度の差が小さくなっているからだと考えることができる。

# 課題7
行列の各要素を2乗、3乗、4乗...n乗としたときに、mulで作ったものとpowで作ったものの速度の比較をする。
## pow計算
### 2乗
```cpp
ans.data[i] = pow(x.data[i], pow_n);
```
### n乗
```cpp
ans.data[i] = pow(x.data[i], pow_n);
```

## mulで計算
### 2乗
```cpp
ret.data[i] = x.data[i] * x.data[i];
```
### n乗
```cpp
for (int k = 0; k < pow_n; k++)
{
    if (ret.data[i] == 0) ret.data[i] = 1;
    ret.data[i] *= x.data[i];
}
```
n乗のmul計算は、nが任意のためLoopを回すことにより実装した。

## 結果
実行結果を以下に示す。
|method|time [ms]|
|------|---------|
|pow  2|0.0708801|
|mul  2|0.00715116|
|pow  3|0.0698837|
|mul  3|0.00928722|
|pow  4|0.0714249|
|mul  4|0.0102422|
|pow 32|0.070118|
|mul 32|0.324644|

## 考察
2乗から4乗にかけては、mul計算のほうがpow関数に比べ圧倒的に速いことがわかる。
32乗の結果を見てみると、pow計算のほうが速いことがわかる。
また、pow関数を使用して計算をする場合、乗数によらず速度は0.007前後であることもわかる。
では、pow関数を使うのとmul計算を使うので同じくらいの速さになる数はどこであるか。
以下の通り、プログラムを変えて実行してみる。
実行の際、pow_nは5から10までを指定してある。
```cpp
for (pow_n = 5; pow_n < 10; pow_n++)
{
    for (int j = 0; j < loop; j++)
    {
        t.start();
        //powで計算
        const int s = x.rows * x.cols;
        for (int i = 0; i < s; i++)
        {
            //計算
            ans.data[i] = pow(x.data[i], pow_n);
        }
        t.end();
    }
    std::cout << "|pow " << pow_n << "|" << t.getAvgTime() << "|" << std::endl;

    //n乗をmulで計算（nは任意）
    for (int j = 0; j < loop; j++)
    {
        t.start();
        const int s = x.rows * x.cols;
        for (int i = 0; i < s; i++)
        {
            for (int k = 0; k < pow_n; k++)
            {
                if (ret.data[i] == 0) ret.data[i] = 1;
                ret.data[i] *= x.data[i];
            }
        }
        t.end();
    }
    std::cout << "|mul " << pow_n << "|" << t.getAvgTime() << "|" << std::endl;
}
```

結果は以下のとおりとなった。
|method|time [ms]|
|------|---------|
|pow  2|0.0707765|
|mul  2|0.00756131|
|pow  3|0.0696491|
|mul  3|0.00825121|
|pow  4|0.071083|
|mul  4|0.00952254|
|pow 5|0.0706823|
|mul 5|0.0520857|
|pow 6|0.0709362|
|mul 6|0.0595956|
|pow 7|0.0701771|
|mul 7|0.0670555|
|pow 8|0.0701397|
|mul 8|0.0777101|
|pow 9|0.0700846|
|mul 9|0.0880053|

以上の結果より、8乗より大きい回数mulをする場合は、pow関数を使ったほうが速いことがわかる。

# 課題8
2つの行列の和を各種型で計算し、それぞれ比較する。
```cpp
mat_add(a_xxx, b_xxx,, ret_xxx);
```
この関数に該当データ型を当てはめ、計算を行った。

## 結果
|method|time [ms]|
|------|---------|
|8U    |0.121711|
|8S    |0.144066|
|16S   |1.95906|
|32S   |2.0142|
|32F   |2.03458|
|64F   |2.09355|

## 考察
unsigned char型の和計算が一番速く、double型の和計算が遅いことが結果から読み取れる。
これより、ビット数が多い計算は遅くなることがわかる。

# 課題9
## ステップ1
整数と浮動小数点の行列に対し、整数で2倍、浮動小数点で2.0f倍、整数をビットシフトで2倍、乗算と除算両方で試した。

## 結果
|method      |time [ms]|
|------------|---------|
|2 mul  (32S)|1.18539|
|2 mul  (32F)|1.95872|
|1 shift(32S)|1.16724|
|------------|---------|
|2 div  (32S)|1.17808|
|2 div  (64F)|3.67325|
|0.5 mul(64F)|2.04155|
|1 shift(32S)|1.17042|
|------------|---------|
|2 div  (32F)|1.19587|
|0.5 mul(32F)|1.19012|

## 考察
小さい行列であったためか、効果を感じることはできなかった。
それぞれ結果を見ていくと、乗算と除算ともに他の方法と比べシフト演算が最も速かった。
floatの2の乗算が最も遅いという結果となった。

# 課題10
floatの行列を3.141f倍する場合と、intの行列を3.141倍する場合と、intの行列の3.141倍を固定小数点で行う場合とshortの行列の3.141倍を固定小数点で行う場合で計算し、比較した。
shortの配列ではオーバーフローに注意した。

## 結果
|method     |time [ms]|
|-----------|---------|
|32F mul 32F|1.35805|
|32S mul 32F|2.24534|
|32S mul fix|1.33749|
|16S mul fix|1.31651|

# 考察
浮動小数点で乗算を行うより、固定小数点で乗算を行うほうが速いことは予想していた。
しかし、蓋を開けてみるとfloatの行列を3.141f倍するのと固定小数点でint行列を乗算するのとshortの行列を固定小数点で乗算する場合の速さの結果はあまり変わらないことが示されていた。
これは、小さい行列であるのが原因であると考えることができる。

# 課題11

## 結果
|method |time [ms]|
|-------|---------|
|add    |0.311793|
|mul    |0.29943|
|div    |0.306912|
|sqrt   |0.598925|
|sin    |3.72721|
|cos    |3.72869|
|exp    |2.08951|
|log    |1.17619|
|sqrtLUT|0.299258|
|sin LUT|0.297868|
|cos LUT|0.297307|
|exp LUT|0.29679|
|log LUT|0.297564|

## 考察
テーブル参照の効果を実感することができた。
また、基本的な四則計算に比べ、sin、cos、exp、log関数は内部的に多項式計算を行っているため遅いことが実行速度からわかる。

sqrt関数に関しては、中で四則計算のうち足し算と掛け算しか利用していないのが高速であった理由である。

また、それらをテーブル参照で行った場合、どれも四則計算より早くなっていることがわかる。

# 課題12
inlineの指示をだしただけでは、毎回inline展開されないとのことであったため、`__attribute__((always_inline))`をつけ実装した。

## 結果
|method  |time [ms]|
|--------|---------|
|func    |0.850623|
|inline  |0.789371|
|hardcode|0.136928|

## 考察
関数をそのまま処理するのではなく、inline展開されたほうが速いことがわかった。
しかし、ループ処理の中でコードをベタ書きするほうが可読性は下がるが、約1/5程度速度が上がっている。
単純な処理では、ループ処理の中でベタ書きをするほうがよい。

# 課題13
行列A、Bの各要素の乗算を行うときに、結果を行列Cに格納する場合と行列Aに上書きする場合の計算時間を比較する。

# 結果
|method |time [ms]|
|-------|---------|
|alloc  |1.60788|
|inplace|1.72584|

# 考察
予想とは反し、上書きをしたほうが速度がはやくなった。
何度か処理をしたが、結果は変わらなかった。

# 課題14
## 結果
exercise 14: loop = 10, size = 512

|method |time [ms]|
|-------|---------|
|col-row|0.290632|
|row-col|1.43105|


|method|time [ms]|
|------|---------|
|i-j-k |314.144|
|i-k-j |212.083|
|j-i-k |359.834|
|j-k-i |406.431|
|k-i-j |211.479|
|k-i-j |410.31|

ループを10回、配列のサイズを512回にして試した。
結果、colとrowの順番だけでも5倍近い差が出ることがわかった。
col-rowの順番の場合、メモリアクセスが容易に行われる。一方、row-colの場合、メモリアクセスのアドレスが飛び飛びになるため、このような速度の違いが出ていると言える。

また、iとjとkの並び順では、何度か試した内いずれでもk-i-jの並びが一番速さが大きかった。

# 課題15
アンローリングの回数を変更することで速度の変化を観察する。
## 結果
結果は以下のとおりであった。
|method   |time [ms]|
|---------|---------|
|no unroll|0.0914482|
|unroll  2|0.0779017|
|unroll  4|0.0741443|
|unroll  8|0.0656382|
|unroll 16|0.0660154|
|unroll 32|0.0645989|
|unroll 64|0.0628068|
アンローリングの回数が増えるごとにかかる時間が小さくなっていることがわかる。
8回から16回のときだけ時間が大きくなっている。理由を考えてみたが思いつかなかった。



# 課題２２

画像の張り付けサンプル

<img src="loofline.png" alt="ルーフライン" width="600px">
図ｘ：シングルスレッドとマルチスレッドのルーフライン．

参考までに，CSEは1.3TFLOPSくらい出ます（試すのは絶対に夜中で．）．

．．．

# 課題２９





# 画像処理課題１

# 画像処理課題２

1回目の課題はここまで．
画像処理の共通の課題である上記１，２を忘れずにやること．
これ以降の課題は2回目のレポートです．

